{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8h6s0OXaALqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2ac162d9-166a-4e83-9357-43b77b7d2c3e"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-17 18:08:21--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3595 (3.5K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-10-17 18:08:21 (69.7 MB/s) - ‘setup_google_colab.py’ saved [3595/3595]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mxyj38u3AFe9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "47CRPhIkAFfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "800afa2c-5e30-40e6-84fc-76319a9428a5"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.11.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxJ5zYU0AFfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "S3ctbxnCAFfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"-\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "lcym5R9RAFfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "a7fe2888-1826-4ada-bdf4-573cd3e5e2c4"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "WZ3jWBuwAFfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c31e98c7-981c-4976-8d7b-adba9c6c0555"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5cce817da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WxeSkcd-AFfa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "dzNMH9_fAFfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32ebf6bd-82c7-42a2-c5bf-89e281231c86"
      },
      "cell_type": "code",
      "source": [
        "#tokens = ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens = set(''.join(names[:]))\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J4W01-ogAFfe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "pXBOvX9kAFff",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "for i in range(n_tokens):\n",
        "  token_to_id[tokens[i]] = i\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "mmIarPILAFfh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32): \n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "JCT_FV2sAFfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "6979dc3b-03ab-4ff4-8bae-a8f4c97fdf43"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[34 39 44 28 33 28 29 50 20]\n",
            " [34 12 50 10 45 48 20 20 20]\n",
            " [34 31 45 16  0  0 16 29 20]\n",
            " [34 12 16 10 51 28 26 26 29]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P6o5xYAwAFfo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "qmTs8H0bAFfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "XhJqSqA9AFfw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation=\"relu\")\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "phW-dQ7JAFfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "_nfD9dvcAFfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb,h_t])\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bn1p-1o7AFf1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "HXZws_NrAFf3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1bwdswgiAFf4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "Cf4PrtZzAFf4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2_RHKf8AFf6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "j41wpvQ0AFf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e3ff55cc-989a-4068-c08f-905316a1b945"
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "\n",
        "from keras.objectives import categorical_crossentropy\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EbjnamYyAFf9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "3bTfEJaIAFf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e7152c14-a27f-43aa-fa67-2ece96356d56"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl4VNX5wPHvLFnISiAh7Kt4AAFB\ncEFFRKmiYqmirVVr3Wpdq1arVlu1tT+1Wty34lJrte6KKFRxQRYBEUV2DjsECBDIvicz8/vjzkzu\nZGaSCZkk3Jn38zx9OnPvnZlzMvLOue99z7k2j8eDEEII67J3dAOEEEK0jgRyIYSwOAnkQghhcRLI\nhRDC4iSQCyGExTnb+wMLCsoOuUwmKyuFoqLKaDbnsCd9jg/S5/jQmj7n5KTbwu2z1Ijc6XR0dBPa\nnfQ5Pkif40Nb9dlSgVwIIUQwCeRCCGFxEsiFEMLiJJALIYTFSSAXQgiLi6j8UCnVCVgDPKC1ftW0\nfRLwIOAC5mitH2iLRgohhAgv0hH5n4DCENufAqYBJwFnKKWGRathQgghItNsIFdKDQGGAbMbbR8I\nFGqt87TWbmAOcHqbtBIoLK3m37PXUVld11YfIYQQlhTJiHw68PsQ27sDBabn+4Ee0WhUKJt2lfDe\nV5t4Z96WtvoIIYRosTlzPuaZZ57o0DY0mSNXSl0GLNFab1NKNfdeYaePmmVlpRzS7KbJJ6fy6bKd\nLFi5hynjBzF0QJcWv4dV5eSkd3QT2p30OT7EQp/T05NJSUmMuC9t0efmLnaeAwxUSk0BegM1Sqld\nWusvgD0Yo3KfXt5tTWrN2grXX3A0dz6ziKfeXsH9VxyL3R7Rb4el5eSkU1BQ1tHNaFfS5/gQK30u\nK6umsrKWZ5+dwZdfzgVg/PgJXHrp5SxbtpQXX3yOpKRksrK68PTTTzB37tcB2+677284nc3XnTT1\nA9Dkq7XWv/A9VkrdD2z3BnG01tuVUhlKqf7ALmAKcEmzrWmFYQO6csKwXJau28e2/FIG9cpsy48T\nQljIO19t5rsN+6P6nscO6cbPTzui2ePy83fz/ffLePHF1wC45ppfM3HiJN5//21uvPFWjj56NPPn\nf0VxcXHQtpKSYrp2zW5VO1tcR66UulwpdZ736XXAm8BC4G2t9cZWtSYCowYbHd6ws6itP0oIISKy\nceNGjjpqBE6nE6fTyYgRR7N580YmTpzEo48+xGuvvcLgwYqcnJygba0N4tCCZWy11veH2LYAGNfq\nVrSA6psFwIadxZzTrp8shDic/fy0IyIaPbcFmw3MN7Kvq6vDZrMzefI5HH/8OBYs+Jo777yVZ599\nJmjb3/72CP369W/V51tuZmdmaiI9s1PZtKsYl9vd0c0RQgiOPFKxZs1q6uvrqa+vZ926tRx5pOLV\nV1/C4XAyder5nH76GWzZsiVo2/btW1v9+e1+Y4lo6NstjT0HKigqqyE7s1NHN0cIEee6d+/J6NFj\nuemma3C7PZx77lS6d+9Bbm53brnletLTM0hPT+fGG69l796DAdsuuujSVn++zXw60B5ac4cg31Xu\n9+dvYfaSHdx58Wh/qiVWxcqV/ZaQPscH6XOLXxsbdwjy6ZqZDMDB0uoObokQQnQ8Swby7AwjkB8o\nkUAuhBCWDOT+EbkEciGEsGgglxG5EEL4WTKQJyY4yEhJkBy5EEJg0UAOkJWRTGFpDe1ddSOEEIcb\nywby9JQE6l1uautkUpAQIr5ZN5B3SgCgrKq2g1sihBAdy7KBPNUbyMur5I5BQoj4ZtlAnpZsBPKK\n6voObokQQnQsywbyxATjLkO1ta4ObokQQnQsywbypEQjkNfUSSAXQsQ36wbyBKPpEsiFEPHOwoHc\nNyKX8kMhRHyLgUAuI3IhRHyzbCD3X+yUQC6EiHOWDeQyIhdCCINlA3mi92KnjMiFEPHOsoFcLnYK\nIYTBuoHcV0cuE4KEEHHO2dwBSqkU4FUgF0gGHtBaf2Lavx3IA3wR9RKt9e5oN7QxyZELIYSh2UAO\nnAss11o/opTqB3wOfNLomLO01uVRb10TnA47DrtNcuRCiLjXbCDXWr9tetoH2NV2zWmZxASHjMiF\nEHEvkhE5AEqpxUBvYEqI3S8opfoDi4A/aq3b5bY9SQl2ubGEECLuRRzItdYnKqVGAa8rpY42Bet7\ngU+BQmAmMA14L9z7ZGWl4HQ6DrnBOTnp/scpyQlU1dQHbItFsd6/UKTP8UH6HB2RXOwcA+zXWudp\nrX9USjmBHGA/gNb6NdOxc4ARNBHIi4oqD7mxOTnpFBSUNTTebqOqpj5gW6xp3Od4IH2OD9Lnlr82\nnEjKD08BbgNQSuUCacAB7/NMpdRnSqlE77ETgDWH1MpDkJho5MjlBsxCiHgWSSB/AeimlFoIzAZu\nAC5TSp2ntS4B5gBLlVLfAAU0MRqPtiSnHY8H6l2SJxdCxK9IqlaqgIub2P8k8GQ0GxWpRNPszoRW\n5N2FEMLKLDuzE2R2pxBCgNUDuczuFEIIawdyp8NovuTIhRDxzNKB3GG3AeByS9WKECJ+WTuQOySQ\nCyGEtQO53Wi+S1IrQog4ZulA7pTUihBCWDuQS2pFCCGsHsjtUrUihBAWD+TeEblLRuRCiPhl6UDu\nlNSKEEJYO5A7vBOCXG5JrQgh4pe1A7mkVoQQIkYCuaRWhBBxzNqB3J9akUAuhIhf1g7k/tSK5MiF\nEPErNgK5jMiFEHHM2oHcW35YL4FcCBHHrB3IZdEsIYSweiCX1IoQQlg6kPvuECR15EKIeGbpQO4b\nkdfLzE4hRByzdiCXtVaEEAJncwcopVKAV4FcIBl4QGv9iWn/JOBBwAXM0Vo/0DZNDSZT9IUQIrIR\n+bnAcq31BODnwGON9j8FTANOAs5QSg2LbhPDk0WzhBAighG51vpt09M+wC7fE6XUQKBQa53nfT4H\nOB1YF+V2hiS3ehNCiAgCuY9SajHQG5hi2twdKDA93w8Mik7TmiepFSGEaEEg11qfqJQaBbyulDpa\nax0qetqae5+srBScTkdL2hggJyfd/zgpJQkAZ4IjYHusieW+hSN9jg/S5+iI5GLnGGC/1jpPa/2j\nUsoJ5GCMvvdgjMp9enm3hVVUVHnIjc3JSaegoMz/vKqmHoCKytqA7bGkcZ/jgfQ5PkifW/7acCK5\n2HkKcBuAUioXSAMOAGittwMZSqn+3gA/BZh7SK08BDKzUwghIgvkLwDdlFILgdnADcBlSqnzvPuv\nA94EFgJva603tklLQ2iY2SlVK0KI+BVJ1UoVcHET+xcA46LZqEjZ7TZsyIhcCBHfLD2zE4zZnRLI\nhRDxzPqB3G6X8kMhRFyLgUBuk5mdQoi4Zv1ALqkVIUScs34gt9sktSKEiGsxEMjtkloRQsQ16wdy\nh01uviyEiGvWD+SSWhFCxDnLB3KnQ1IrQoj4ZvlALiNyIUS8s34gl/JDIUScs34gt9txuT14PBLM\nhRDxKQYCuSxlK4SIb9YP5A4J5EKI+Gb5QO60+9Ykl0AuhIhPlg/kDakVKUEUQsQn6wdySa0IIeKc\n9QO5d0ReL7d7E0LEKesHct99O2VELoSIU5YP5E5fjlwudgoh4pTlA7nDLiNyIUR8s34gd0jVihAi\nvlk/kEtqRQgR56wfyKX8UAgR55yRHKSUegQY7z3+Ia31B6Z924E8wOXddInWend0mxmeP0cu5YdC\niDjVbCBXSk0EhmutxymlugIrgA8aHXaW1rq8LRrYHFk0SwgR7yJJrSwALvQ+LgZSlVKOtmtSy/hS\nK3LfTiFEvGp2RK61dgEV3qdXAXO828xeUEr1BxYBf9Rah42qWVkpOJ2H/juQk5Me8DwzoxMAaWlJ\nQftiRaz2qynS5/ggfY6OiHLkAEqpqRiB/IxGu+4FPgUKgZnANOC9cO9TVFTZ8lZ65eSkU1BQFrCt\nqrIWgMKiyqB9sSBUn2Od9Dk+SJ9b/tpwIr3YeSZwDzBZa11i3qe1fs103BxgBE0E8mhzOqT8UAgR\n35rNkSulMoFHgSla68LG+5RSnymlEr2bJgBrot/M8HxVK/UyIUgIEaciGZH/AsgG3lFK+bZ9BazW\nWn/oHYUvVUpVYVS0tNtoHGRELoQQkVzsnAHMaGL/k8CT0WxUSzi9qx/KMrZCiHhl+ZmdDYFcRuRC\niPhk/UDuNFIrdTIiF0LEKesHcpmiL4SIc9YP5E6jCzIiF0LEK8sH8gRfjrxecuRCiPhk+UDesNaK\njMiFEPHJ8oG8YUQugVwIEZ8sH8j9I3IpPxRCxCnLB/IEmRAkhIhzlg/kvqoVCeRCiHhl/UBul5md\nQoj4Zv1A7vTlyGVELoSIT5YP5A67HZtNJgQJIeKX5QM5GAtnyRR9IUS8iplAXiczO4UQcSpGArlN\ncuRCiLgVI4HcLoFcCBG3YiKQJ0ggF0LEsZgI5A6HTerIhRBxKyYCuYzIhRDxLCYCudMpgVwIEb9i\nIpAnOu3UuzwSzIUQcSkmAnl6SiIAZZV1HdwSIYRof85IDlJKPQKM9x7/kNb6A9O+ScCDgAuYo7V+\noC0a2pTMNCOQl1TUkJWe1N4fL4QQHarZEblSaiIwXGs9DpgMPNHokKeAacBJwBlKqWFRb2UzMlON\nQF5aUdveHy2EEB0uktTKAuBC7+NiIFUp5QBQSg0ECrXWeVprNzAHOL1NWtqE5ETjxKKmTnLkQoj4\n02xqRWvtAiq8T6/CSJ+4vM+7AwWmw/cDg5p6v6ysFJxOxyE01ZCTkx78np1TAEjulBCw/+vv81iy\nJp87fnUsDrvtkD+zo4Xqc6yTPscH6XN0RJQjB1BKTcUI5Gc0cViz0bKoqDLSjwySk5NOQUFZ0Paa\naiOlcrCokmffXkG/7ukcPyyX6f/9AYCNWwvIzux0yJ/bkcL1OZZJn+OD9Lnlrw0n0oudZwL3AJO1\n1iWmXXswRuU+vbzb2pXvvp3VNS4+XbYTgOOH5fr3e2TSpxAihkVysTMTeBSYorUuNO/TWm8HMpRS\n/ZVSTmAKMLctGtqUxARvIK+t92+rrXP5H0t9uRAilkUyIv8FkA28o5TybfsKWK21/hC4DnjTu/1t\nrfXGqLeyGf4ReW1D8P7Lq9/5H9fVSyAXQsSuSC52zgBmNLF/ATAumo1qqYQE4+JpVU3DiDz/YEMu\nXhbUEkLEspiY2ZnoDB6Rm0lqRQgRy2IikCd4A3mVKUduJoFcCBHLYiKQ+yYEVVRJIBdCxJ+YCOQp\nSUYgL68KPUVfbswshIhlMRHIExPs2G02yqtCr34oI3IhRCyLiUBus9lwezxU1cjFTiFE/ImJQN4c\nCeRCiFgWM4F8SN/OYfdJHbkQIpbFTCA/64R+Yff5Zna63R6eeHclS9bsba9mCSFEm4uZQJ6VFv7O\nQL7Uyq6CclZtOciLn6xrr2YJIUSbi51AntF8IG/JKogLV+3h1f+tb22zhBCizcVMIPfVkofiy5F7\niDyS/2vOBhaszKcmzLR/IYQ4XMRMILfZbPTrHnrhdd+I/Kn3VrX4fd2ymLkQ4jAX8R2CrODPvx7L\n8g37Kaus443PG1bTrXO5qal1UVzeMPPT4/FgszV/+7c6lxtr3ltICBEvYmZEDmC32ThuaG5QmqW2\nzsXvnloYsO31zyNbNt0lpYtCiMNcTAVyH99qiD7frN4bdHOJeT/s9j/efaCC66bP572vt/Dtun0B\nx9XJZCIhxGEuplIrPk5n5L9PL89exzerjbryOUt3AFBUVuPf75JALoQ4zMXmiNwRebd8QdzsnXmb\n/Y/lNnFCiMNdbAbyCEfknggqUvYcqODNLzZxoLiqtc0SQog2EdeB/MdNB5o9ZsbH6/h8eR53vLCE\nzbtLAvbVu9x8+f0uSitDr4MuhBDtISYDeXKiI6Ljnv5gdYve98H/fB/w/Ivlu3jj84289PE6qTcX\nQnSYmAzkXTOS2+Vz9hZWALBmWyHXT5/fLp8phBCNxWQgT0xoGJFPObF/m32OeXnc2nq3f1T+xtyN\nPPHuyjb7XCGEMIuo/FApNRz4CHhca/1Mo33bgTzAtyjJJVrr3RwmzGkWp8MecJOJUUdk8+Pm5vPk\nZk+8u5Lrpg4nKdERdMMKl8uN3engyx92ta7RQgjRAs2OyJVSqcDTwJdNHHaW1vpU7/8OmyAOUGG6\nj+dTN5/sf3zt1KM4ZVTPFr/fqi0HWbbBmDTUeNZn45s8u9xu7n9lmb8+vTk1dS6qauojbovH42HX\n/nJcbimRFCKeRZJaqQHOBva0cVuiaurJAwDok5vm35ac6CQ3y1g5ZfiALjjtza+1Esq/5mzg5dnr\ngkbkjZ8fLKlm5/5y3vt6S0Tve+cLS7jh8QURt+O7Dfu595VlvDsvsvcXQsSmZlMrWut6oF4p1dRh\nLyil+gOLgD9qrcOWcGRlpeB0RlZVEkpOTugVDhu7+ryRXH3eSNZtOxjw2kd/dwpVtfX0zE4jOfXQ\nL4p+s3ovo4/MCdzodAS0Lz2jYbmtnJx0Nu8qZtf+ck49pnfI9yytMMoYs7PTsNlsvP25prSilt/8\nbETAcR8v3MrGvCKSE42v79v1+7jpomMOuS+Ho0i/51gifY4PbdHnaEzRvxf4FCgEZgLTgPfCHVxU\nVHnIH5STk05BQVmLXpOdmsC5J/Zn9JHZ/tcmAAUFZU2ejmSlJwVM1Q+ltCJw/y2Pz+eVu07zP9+z\nt9T/uKCgjFsfNypbctMTye5sBPk12w7Sp1s6mamJ/mPz95aQ4HTw+qcbAPjZSf0DPmfGTKNs8sTh\n3QEjxdPSv0s436zO5/Pledx1yTH+H4r2dijfs9VJn+NDa/rc1A9Aq/+laq1f8z1WSs0BRtBEIG9v\nNpuN804ZGHZ/WqcEyk15dJ8LJgxq9pZwW3aXBm3L21/uf1xRHTrfvTW/lOzOndi5r4zH3l5JdmYy\nRw3o4t9fU+cmwXTW4nK7sdtsFJXV0Nl0S7uaOuP6ciQzVCP18mzjrkhb95QyrH8X3G4P5dV1ZKQk\nNvNKox0HS6rpmpkc0RLBQojoaFX5oVIqUyn1mVLK9698ArCm9c1qP3/45WjGj+wRtL1TE3ccasp9\nryzzP15pqogxTxgqqzR+OA6WVANwoKSa+T82XIKorQu8K1FFdT3//lRz+3OL+WFjgek4d9B7R0ui\n94fkqfdXcctTi5o9OwFYtDqfO15Ywtzv8qLeHiFEeM1GK6XUGGA60B+oU0pdAMwCtmmtP/SOwpcq\npaqAFRxGo/FI9OmWxhVnD2XhqnwAeuekktYpgaH9slr93vNWNBTwmBffeuPzjUwY1ZOdptG7WW29\nO2CUfcfzi/1Be+WWhh8H34i8LYpWauuN9161xbjGsK+wkqz08PdFBePiK8Cy9fs487i+0W+UECKk\nSC52fg+c2sT+J4Eno9imDuGrKR+juvkrXqZNGMj787cGHDeoVwYnDe/Ba5/pFr1/41UUP1q0jdlL\nQpcl1ta5Aicb1TW81hy0N+YVA61PrWzaVUxSgoO+uQ05OPNnAkSSKfG4jXbYD7EaKJy6ehf3vPgt\npx3Tm8nHyw+EEI3F5MzOQ3HNT4dx4amDAgJFblZK0HEDe2RycohUTHM+WBD4gxAuiAP8Z65mz4GK\nkPuKy4NTHO5WZlYeev0H7v/XdwHbfCNyn0hy3i5fII9yfjxvfwUHSqoDlhcWQjSQQO6VnOjkrBP6\nkWSa3l/TKFcNMGFUT5wOe9DCXJPG9mb04Oyw7//1isjnSW3ZXcrj7/wYct/6HUVB2+yNvsVvVufz\n2bKdEX2WeTRvftz4DMLtDdL/nLWWWd9sC/levmMcUR6Rh/tdcHs8bN1TGlS/L0S8kUDehMYBaazK\noWd2KgB3XXIMxw7p5t/3y9MHc9U5w6L22aWVwZU04dTWuSkxjdRfnr2et7/aHPYiaElFrX+fOWCb\nHze+4OrL23+7bh8zF4YO5C5Py1MrkaSFwgXyRavy+dtry3l/vkyIEvFNAnkTxg7pRrfODZN6sk2P\n++amc+3Uo/zPbTYbnZIcjFGNJgm1kzdC3Ey62FRpUu9yM/e7PLbsLuHWpxfx6pwNeDwe8g821PX/\n/b8r/I9rG43I6+rdzY58ffn7SAP5ix+v5Y8zlkZ0bCgbvGcnKza2bL2caHK7PezcVybLGIsOFZP3\n7IwWp8POw9eOo7q2nqXr9jFuWPeA/TabjcnH96V7lxT/8xvOG8Fv//G1f3R796VjmLs8j+Xeio62\nslwXUFxeE1Db/sC/l/P4TSfjcru58YkFARcwF63OJ6dzMh+aRtfb8hteGxTIXS52FQTn7T0eD+/M\n28zwgV0bUisR5siXrN3nf4/Fa/bSMzuVAT0ygo5rvKaN/7O9/9+RJesfL97OR4u2cdlkxamjenVc\nQ0Rck0AegeREZ9h/pD+feETQNnNgOaJ3Jr27pbJq84Gg4AhGFUyoiUWH4vfPfBPwvKSilsrqem58\nIvT6LZ80ccG1cWplx94yZswKniCVf7CSz5bl8dmyhtpx34h8X2El+4qqGDmoa5PtLi6v9U9EMs+M\n9Ql3JuBPy7Qwkh8oruKp91dx6RmKI/t0btFrG1vhretftfmgBHLRYSS10gYa13UnJzoZ4q1L79st\nLWDfyEHhL5D+4aJRrWpHYoKdl2eHn53a1I2l6+rdAcF8257QPzahgqwvkP9xxlKeeHdlQP7ex7zt\ntme/CdoPxpLB/3hrBfVhynJ8m5vK5Hg8Hpau2xswoemTJdvZVVDB8x+1fu6aw2F8uKu1pUOiSdGc\nvRyLJJC3gVDVK+mdEgBwOCL/kw/t34XMtNBT46+eMrTZ19fWuVm7rTDizzPL21/O9LcbKmcqGy2v\n+9aXm/jPXB0ygG3LLw1IJa3fUcS7X2/2p148Hg+3PhM6eJut2nKQdduLcDUzIm+qNHJjXjEzZq3j\nodfNt+mzeV/fbBMC7C4oZ/aS7QFBxfd9mn/QZi3axhtzN3Zo3jxvfzn7W7GuERj1+zMXbvXPQO4o\n3+v9XPX3eezcF1/rsrSEBPI2cOU5RpBNTGj48047dRCjjsjmynOGMtZU7dJcUqBndlrI7Rmpza99\nAsG57kit31HEpl0NN5tunB+f+10e837YzZtfbAp6bWFpDc/NbBjtzvh4Hf9butO/vECosk4zvaOQ\nvYUNQag+TI6cEJkVj8fDzIVb2e5dsKzIO/I/YApG/uNDBNrC0uqQZxCbd5Xw55eX8f78rf6LrIB/\nKeT1O4r8wXzmom18+cMunv8w9Ih/x94yPlm8HZe74azH7fYErNPTGrV1Lu57ZRl3/fPQLyQDfL1i\nD7O+2c6T77X8bld7Cyv5ZnV+0PZdBeW8M29zi9bQ/4938l1LSnjjjQTyNpCU4OCF2ybw9M3j/ds6\npyXxuwtG0is7lZ+MNZaxnXrygIAgZB5lP3D18QCccXy/kJ+RnHB4XN7YvLuk+YO89hVV8tpnmoOl\nTa/bcvtTC7nbVM3yxfKG/HtJeQ0vfLSGorIa/4jX/GO4aVcJs77Zzl9fXU5dvSvk5CTfFt/JxLvz\nNnPH84upq3dx+3OLA84WDhRX4XK7edA0ovcthjZ7yXY27Cz2b/ct8+DzvWldnMLSaiqqjZLSv7z6\nHR8s2MpvHvmaa733ev3XJ2u575Vl/LjJqMDxeDwsWbOXwtKWj4ZbsqZ9U3ztDXWRuzl3z1jKy7PX\ns68w8KzggX8v59Nvd7J8Q0HA9k+/3emfqdyY2/+DLQuxhXN4RIMYZL5vaGODe3fm8ZtOJj0lgU+/\nbZi4c+LwHnTvkkrP7BT/ErKTjutLsgPWbi9C9e3M9LeMdEenpKbXdD9hWC5L1+2LQk+ix7fcQXET\nC3AdKK4K2mYOls9/tJaNecW4XB48If6Bm1NAv/3HfC75yZFB7+c7vryqjrp6F//zfgfmPPrrczVH\nDejC0++vZtLYwPXjS7zrxjdevqG8sjbos+pdbjweuP25xUDoi7kej4eZ3lr47XtLGTU4m415xbz4\nyTqy0pOYfsNJrN1eyIcLtnLLhUeT5k3ThROtfH1L0oDhND778l2Xqapt+J5KK2r9s3bNfx+Px4PN\nZjOl0FrdnIi43R5enr2O44bmcvQR2dTUufjHmyv4ybF9OG5obtjX7S4op0d2atRnNkdCRuQdJDM1\nEbvNFpRaGdgzI2gdcNU3i/NPGchR/btw3+XHcvGkwfTKSWNw78yg9738rCE89/tT/OmdSDQXGKKt\nujb87ezueGFJk6/1jdq+31jg/wdeVVPPH55bzIKVe/iw0VIIuwsC0xVujycgiHwfYjVJgK9+2M3T\n7xvrvn+xPPAerG98vjGoqgdC189Pf+tH7n352yb7ZA68s77ZTv7BCn9Nv+/HZfpbP7J1TykLVh7a\njbp2FZQzc+FW/v3pBirDLK/cWEKIQH6wpJqn318V8KPn8XioqQ2dLgs7y9f0WxMq1VZUVsNVf5/H\n58vzQv5g+yxZs7fFufO12wvZsTf8a7btLWXJ2n08+d4qdu4rY/WWg2zZU8oLH60N+5ola/fy55eX\n8fE321vUlmiRQN7Bxh/dk77d0rjlwqMjOr5f93Qmje0DwB8vHRO0f3DvTJITnTgddlQEpXWTxvZu\n94qAaJ0i+wLAgZJqDpZW8+r/NgTlmRuPTr/8fhdL1zacqZjLJktDjKjDCbXWfKiRmM4rZl9R8FmG\n2Z2NfryWrN0b9tjmvqtw1x/ufXkZs77Zzvwf9zB7yfawr9+1v5x3v95MaUUtCc6G8PDkuyv5YWMB\nb321iRWbDvCSaa3+mQu3cd1j81m2fh+7D1T4c9oQEK8D+2F6bP5R9J2h+lb5fPOLTXgIPSKvqqnn\nxU/WBa0T5LNhRxFL1+31p4gAampdTH/rR/7y6ncs37A/ZN7dbfpv5v5/fcdbXwVfB9qYVxzwg+i7\n/rNsfcN/W/NW7GZrmGqvaJPUSgdL65TA/VceF5X3euzGkwJuPBHqH9HVU4ZSUlFL1wzjZhYpSU6W\nrAkfOMC4aNt4NUSA3jlp9M1NY1DPDP4zN3hmqdmQvp39KZJQ68UcCnPKJRxz3rqwtDro4qx5ZPaP\nt0KvbxNKqEXNbDZbs5Uqoco1G6/1Hsnv6oxZa7HZbJxxbB9enr2OG88fQbesFO55MfAC566Ccrpm\nBN7ScO53eRzRO5PRgxtmIZc4aMYvAAARh0lEQVRX1ZGc6OCDBVv5cfMB6urc9MpJ9e9fueUgK7c0\n3DZxb2ElHo+HjXnFfLx4O0DIEWu4yVzmSqQa039b78zbTEZqQsAIv6HMNDCSbzFdn3G53ThMiw5V\n19bzyJvGWU33Lik8eM0JeDyegFJX3wX544fl+u8/UFJRG/AjBcbFezO9s4i//3cFQ/p25o6LjVss\n1ntTRk7vWUxpRa3/By1UOi3aJJBbXEqSk8qaek4c3j0giIdz4vDglRt75aQFXGjyLekL8MtJg5m1\naFvIQP7Xqxp+gJoL5O4o5G3vvnRMwEXHlvLlqaPhhRA16Gu3HWy25M93X9amNC73Mz9/f/5WEpwO\n//UP3+j9rn8uDXl7wntfXkZjLreHp99f7Q8whaXV3P7cYsaP7OFPe23YWURZiDtn+RSV1fDF8l28\n+WXwaNWs3ludsjGvOODC+H+/2MTUiYPJ218eMKMY4KVP1gc8N+fIfUH0z78ey2PvNFTT1Nd7cJgK\nucw/Dr4KqD0HKoLKaMEo1fRNDPtwwRYKipu+wLxjn3HWZx5I+H6gfYHcPEcj/2AFDoc9YLmPaJPU\nisU99NsTuO/yY7l6SvCCXZf+5Ej6dkvj/iuObfI9bjx/BH1zG8ocU5Ibft9/MrYPqcmtz6FPPiF0\n9U1LpHY6fMYdoVIra7cX8fWPTeewI/kxaXyROr8wcPT/VpjgGcldnMyqauqprK73X7RduCqfFO93\nvauggm+buVjeXBCHhhH5w2/8wHtfBy5utrugnPteWRZynSAzf44cG299ZVwUbfw38K32WVRWw77C\nypC17+H+PubUS1VN06WxFdV1If/+dd5+Jjhs1NW7A46558VvuauZaz+tdfj8yxCHJD0lkfQw99Ps\n3S3Nn7aZfsNJATlPs7ROCdx/xXFc+fBX/udmv56seOydlZx1Ql8+WRx+Wj8Yp6mhAkC/3HT+cf2J\nIQPZ0YO6Bpy2hxPJzaB/Nn5A2NUZATJSElq0suThoLngcqhuemIh/XukB+Rxo70kcEV1XVAJos/6\nCCer+c7mPl2203+Bv3FQnrloG8XlNWF/SL/XBVSFGI0DVFbX8+GCrai+nQNupRjKTU8sDLndlypy\nOOx8vHhbwEX09iCBPE40d5s2s05JTu68eDRdM43c6tD+XXjxjokAHNW/S8AqiT7X/HQYMxduY6zq\n5g/kvzpT+fOEiQl2UpKc9M1NY+e+hguSJ4/swSU/OZL8gxUsXJkfcHu8xhqvAR9KTmbTp6+dkhsC\neVKiI2y1xeHk+Zltcxtc33ruZqsi+EFtCV/lTygvRrhEgvmaga8KpnHeGmjybOjZD1czbULom7Dv\nKijns2V5fNzCzFtKkpMVGwvYV1Tln7S2fkdR1K4BtYSkVkQQj8eD6ptFdoigmBZm9H/CsO48/Ntx\njBrclbEqh99NG8nE0Q2LSCU6HdhsNm6/aLR/2wWnDuLyyUNISnDQv3sGvzpTcVaYW7lNGtubJFMg\n7xxm6YLmpso67TayM5PplZPK/3knXaV6U0lH9MoMuQzx9BtOClmPDm1Xunndz4bzx0uPaZP3thrz\nBeR87+j+UJY/CJUOA6NS51Dkdknh6Q9W8868zeyIoATyjc83tlmFmIzIhd+Zx/Xhs2V5Td54Ottb\nAXFkiBp2AIfdzvXnjQja7vQuLmUOfH26pQXVXp89rh9VdW5G9M9iYK9MZi/ZzsTRvejR1aigOOuE\nvnTPSiElOYFnPwwc7dkwzhgeuW4c5VV1/PXV5UHt6JKRzC0XjsSDUQXx8LXj6JKexNY9pXTJSOIT\nbwWGWVZ6EqeP6R0yl3v+KQPJzkwOuPAGgWcjkZo4upf/jGRAj/SgapPD2U9P6s+sdqihLimPvES0\nMfPkO7O12w9tBN34Im1zvvx+F317ZDB+ePfmD24hCeTC7+cTj2DycX3JbKL6JSnRwdO3jCfR2Xya\nA4yAtvdgZUDt+MCeGWzdU0p2ZnCgSk1O4LZLxlBQYIxwLp4UOBK+8FRj2eBFprLC538/IWC0DtA1\nI5k+3dIC6spTk51cNWUoNtNELF8lga9q4bzxA9lbWBV2ujjAySN6sMi0jki1KT1z6RlHMnxAF7pl\npUQUyH1/C4DxR/fwB/KuGcmWmpI+rH+Xdgnk0dC3Wxo7o7SuTUvt2FsmgVy0LZvN1mQQ92lJFYs5\nveJz+0Wj2FdY5R9lH4pjjsxm0apMpo4fGBTEwejLVecM9U8WibSWNzMtibsuOYY/vfQtew5U8NiN\nJ/n3JTiNPH9aSmD/zSfLpx0TOJ0/lE5JDv8FTPPMx0Sng79dfTxOpz0oiCclOJpdbKw9XXPuMGZ8\nbNRb/+6Cka1e1z0aBvTIiGiUbF5wLjszOWBBtaY47LZWL39w3fkjKStteoLYoZAcuWh3yYlO+nVP\nb9V7pCQncNelY5pMA7XG/Vccy/O3TQiozX/21lN49PoTA+qBh/bLYtQR2Zw8sgf3XBY40/bkET38\ndcVmd5tm5NptNu7+1RgunTyEHl1T6JmdGrLe+I6LRwdt+7/fHM9vpgwLurlJotPOdT8bzs/GD+Di\nSYP9k118mrpJeCQuO1NxwlHdufmCkfz512MZdUTr3i+Uuy8dw19aOFHu4kmDA56bJzSZdclo+E7T\nUyIflPz92nH+x1eeHfkSGGd7S28vOn0wyUltM3aO6F2VUsOBj4DHtdbPNNo3CXgQcAFztNYPRL2V\nQhyCltwEujGnw07j7JEvKI87qjvfbdjP+KN7kOu9zV+of9hXnjOUK88Zyn/maub90FCN0ysnzZ9S\nsdttHNErk3GjevvTSWa+xc9yszrROyeN9JQEbpo2Ahs2khId9OiaSolp0SmA52+bEDCiP31Mb2rq\nXFz/2IKAfnTNSGb4wC6cMCw3ZCVSOD26Gn0+OsIAftO0EXRJT8aDJ+R1i8YevnYc3Tp3Crig+cwt\np3CgpIon31vFr85QuNxunjUtE3zS8O4B3/etPz+arhnJ/Omlbznj2D7kH6xE9e1MSpIzoMRy8vH9\n/FVBT908nt892VBeeOfFowP+LuaqqWH9s3jmlvHMX7mHd+eFvvn36MHZnHZMb44a0IVTR/X0V4G1\nhWYDuVIqFXga+DLMIU8BZwK7gflKqfe11uFvSyNEO+mVncr4kT0CpqJHQ1Kigz/8MniEHM4vTx/M\n1JMHsHt/OTne0baveiHsolJeV587jCvPGYrTYQ+YSWuWmZrI87+fwHWPzadH15SgtIzNZiM50UlG\naiKlFbX+z3Q6bPx68pCQ73nZZMVbX2yitt7NtVOP4pgjc7jm0a+9bW76RP7mC0aSnZnMn72zSnvn\npPn7ndM5maoaF+VhZo2eOrqX/4zEbrPx0G9PIDnBQUqyk77J6Uy/oSHVZS4fHTukW8DZz4iBxu0F\nQ6XUyqvq2HOwkpEDuwbchjCtUwIv3zmRq/4+z2h3tzSuPHsor8xZzxVnDwlY0TQxwUFKcgLdOqeE\n/Ttcdc4w/+S67Dac1QmRjchrgLOBOxvvUEoNBAq11nne53OA0wEJ5KLD2Ww2rmjBKXBbcTrsZKQk\nktG/i3/bkL5ZbMsvQ/VtOrdst9mwO5o/s0hKdPDIdeOanDT1yLXjqKlzUVXrYm9hJb86UwUdc+3U\no0jvlMDQ/l04bkguefvLUH2N9NW9l4/lh40HGNQr+AbZYMwJWLQqn2H9s0gwnc6Yr6k8/NtxeIBH\n/rsi5AXlxj3NzQofKB/8zQnsOVhBv9x00jol4PZ4OH5YLmOObPqHO61TApeZ+n7zBSP9KTSbzYbT\nYaPe5SEpwcHJI3swclBXf149rVOCf10aaPo2g8nNLDUdTbZI6xqVUvcDB8ypFaXUicAftNbneZ9f\nBQzSWt8d7n3q610eZ4QVD0LEqrp6F2u2HGTkEdlRWfe7tX7z4OfsPVjJrH/8NGrVMt+uyWdbfikX\n/ST4BwOMs5J7nl/Mau9KhwBnndif66dFthJoWykuq6GsspY+ucHXcSqr66ioqicnyxhhf7smn7/9\nyzjzuO3iY5j+3x/8x348fWq0mxb2i4l25r3Z/wKKWnEfwZyc9JB5xFgmfY5dvbt0otC7jkpH9/mv\nVx5HTZ2LAweiV5Y3MDeNgblpYfuVk5PO76YNp7SijvteWUZ5VR3V1XWHxXefbKfJdvj2ueuN1E5i\ngp20RtVToV7fmu85Jyd8gUBrhwJ7AHNRZC/vNiGEhTgd9qgsjtZSDrudrPQkLj3DmC9w6qjgctXD\n2aCexozkxhU2T5lu89geWjUi11pvV0plKKX6A7uAKcAl0WiYECJ+HDc0l2OHdLPUJCgwcuq+uRK+\nG35D+991K5KqlTHAdKA/UKeUugCYBWzTWn8IXAe86T38ba1102tSCiFECFYL4o0F37ix/TQbyLXW\n3wOnNrF/ATAu3H4hhIgHfXLTGHdULmOHdGv3z5Yp+kIIEQV2m43fnHtUx3x2h3yqEEKIqJFALoQQ\nFieBXAghLE4CuRBCWJwEciGEsDgJ5EIIYXESyIUQwuIkkAshhMVFvIytEEKIw5OMyIUQwuIkkAsh\nhMVJIBdCCIuTQC6EEBYngVwIISxOArkQQlicBHIhhLA4y9xYQin1OHAC4AFu1lp/18FNihql1CPA\neIzv4yHgO+A/gAPIB36lta5RSl0C3AK4gRla65c7qMlRoZTqBKwBHgC+JMb77O3LHUA9cC+wihju\ns1IqDXgNyAKSgL8Ae4HnMf4dr9JaX+c99g/Ahd7tf9Faz+mQRreCUmo48BHwuNb6GaVUHyL8fpVS\nCcCrQD/ABVyhtd4a6WdbYkSulJoADNZajwOuAp7q4CZFjVJqIjDc27fJwBPAX4Fntdbjgc3AlUqp\nVIx//JMwbr13q1KqS8e0Omr+BBR6H8d0n5VSXYH7gJMxblI+lRjvM3A5oLXWE4ELgCcx/vu+WWt9\nEpCplDpLKTUAuIiGv81jSilHB7X5kHi/t6cxBiQ+Lfl+LwaKtdYnA/+HMaCLmCUCOXA6MBNAa70e\nyFJKZXRsk6JmAcZIBKAYSMX4gmd5t32M8aUfD3yntS7RWlcB3wAntW9To0cpNQQYBsz2bjqV2O7z\nJOALrXWZ1jpfa30Nsd/nA0BX7+MsjB/tAaazaV+fJwL/01rXaq0LgB0Y/21YSQ1wNrDHtO1UIv9+\nTwc+9B77BS38zq0SyLsDBabnBd5tlqe1dmmtK7xPrwLmAKla6xrvtv1AD4L/Br7tVjUd+L3peaz3\nuT+QopSapZRaqJQ6nRjvs9b6LaCvUmozxoDldqDIdEjM9FlrXe8NzGYt+X7927XWbsCjlEqM9POt\nEsgbs3V0A6JNKTUVI5Df2GhXuL5a9m+glLoMWKK13hbmkJjrM0bbuwLnY6Qc/kVgf2Kuz0qpS4Gd\nWusjgNOA1xsdEnN9bkJL+9qiv4FVAvkeAkfgPTEuHsQEpdSZwD3AWVrrEqDceyEQoBdG/xv/DXzb\nregcYKpSailwNfBnYr/P+4DF3pHbFqAMKIvxPp8EfAagtV4JdAKyTftjsc9mLflv2r/de+HTprWu\njfSDrBLI52JcLEEpdQywR2td1rFNig6lVCbwKDBFa+278PcFMM37eBrwKfAtcKxSqrO3GuAkYGF7\ntzcatNa/0Fofq7U+AXgJo2olpvuM8d/waUopu/fCZxqx3+fNGDlhlFL9MH681iulTvbuPx+jz18B\n5yilEpVSPTGC27oOaG+0teT7nUvDtbJzgXkt+SDLLGOrlHoYOAWjZOcG7y+85SmlrgHuBzaaNv8a\nI8AlY1z4uUJrXaeUugD4A0aJ1tNa6zfaublRp5S6H9iOMXJ7jRjus1LqtxjpM4C/YZSZxmyfvYHq\nFSAXo7T2zxjlh//EGER+q7X+vffYm4BLMPr8J631lyHf9DCllBqDcd2nP1AH7Mboz6tE8P16q3Re\nAgZjXDi9XGudF+nnWyaQCyGECM0qqRUhhBBhSCAXQgiLk0AuhBAWJ4FcCCEsTgK5EEJYnARyIYSw\nOAnkQghhcf8PK4HPdm1JeHwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5cc581a240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "voGNsmUEAFgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "LLeIbgjdAFgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "LVkNtdZEAFgE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "FzGilWEaAFgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c4ab26f0-59d0-4af7-b0f0-ea377ba286c4"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Jeren\n",
            " Maltie\n",
            " Sonwonie\n",
            " Sinly\n",
            " Remand\n",
            " Locele\n",
            " Hotrila\n",
            " Deili\n",
            " Caisea\n",
            " Gimal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "J1YeDqhYAFgI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "cc4f03c8-0f09-4a48-e012-efd7ad3a119d"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpra\n",
            " Trumpo\n",
            " Trumpy\n",
            " Trumpie\n",
            " Trumpa\n",
            " Trumpwe\n",
            " Trumpe\n",
            " Trumpene\n",
            " Trumpw\n",
            " Trumpie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXnSD_IKAFgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "D0noCNUoAFgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"lP6O4J4gvy7p7wsB\"\n",
        "COURSERA_EMAIL = \"wlwu1993@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "qs1P7JMJAFgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5200645f-2b24-4e32-f9a6-6f2d82dc7343"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WG0X-OWFAFgR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "XUQ_Ii80AFgR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "vvKKrN-QAFgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f0f8e0e2-886d-47b0-adda-45cfad393342"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jxl0iGqbAFgT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "rVzSZbLvAFgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9717c59a-cf77-48ac-eedf-ab8b2f80b4b6"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "C7lubYqfAFgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3b16e991-3b06-4021-c2b8-de5eb568ed93"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}